\documentclass[11pt,a4paper]{article}
\usepackage{amssymb}
\usepackage{multicol}

% document properties
\title{Machine Learning}
\author{Andrew Ng}
\date{}

\begin{document}
\maketitle

\section{Problems}
\subsection{Supervised Learning}
\paragraph*{Def:} Give the algorithm a dataset in which the right answers are given. 
Algorithm then can produce more right answers. 

Learning can be used to solve two types of problems:
\begin{itemize}
\item \textbf{Regression:} predict a continuous value output.
\item \textbf{Classification:} predict a discrete output, ie. what label to attribute to the data.
\end{itemize}

When learning, a data point can have multiple \emph{features}. 
A data point is basically a vector of features, with each feature either a scalar or a vector itself.

\subsection{Unsupervised Learning}
\paragraph*{Def:} The algorithm has to discover structures in the data on its own, without input from the user.
This is usually done by \emph{clustering}. 
Clustering is used for example to detect patterns in news headlines, friend groups in a social network, or even on star positions in space.

\section{Linear Regression}
Express the problem by means of a model and based on the model, define a cost function depending on the models parameters. 
If the parameters are deviating form the observed measurements, the cost function will produce higher values. 
Now the task becomes, to find the parameters that have the least cost.

\subsection{Gradient Descent}
Gradient descent is an algorithm that tries to approximate the parameter vector $\theta$ that minimizes the models cost function $J$.
It does this by descending along the gradient vector of the cost function in parameter space.
\paragraph{Hypothesis:} is the way we model the problem. 
The following is an example of a linear function trying to fit the data: $h_\theta(x) = \theta^Tx = \theta_0x_0 + \theta_1x_1 + \ldots + \theta_nx_n$.
As with any linear function, there has to be an offset element, which is why we introduce $x_0:=1$.

\paragraph{Parameters:} the purpose of \emph{gradient descent} is to estimate the parameters, $\theta$, of our model $h_\theta(x)$.
These parameters are represented by the vector $\theta
= \theta_0, \theta_1, \ldots, \theta_n$, with $n$, the number of features plus one.
This plus one, is the offset parameter, as previously described.

\paragraph{Cost Function:} is chosen to model how well the estimated model/parameter pair fits the existing data.
The \emph{cost function}, is also the one, who's gradient is being descended in the search for the \emph{global minimum}.
Depending on the problem, the choice of \emph{cost function} has great impact on the parameter estimation, as the descent can even be stuck in a local minimum, never properly converging.
This is also why, the choice of initial values for $\theta$ can play an important role if the algorithm converges.
\begin{equation}
J(\theta)=\frac{1}{2m}\sum\limits_{i=1}^m(\theta^Tx_{i,:}-y_i)^2
\end{equation}

\paragraph{Implementation:}
Although \emph{gradient descent} can be computed using only the cost function, by using central differences to approximate the gradient vector, the most efficient way to implement it is using the derived of the cost function. 
Evaluating this gives us the actual value of the gradient for any parameters vector $\theta$.
This should work for just about any cost function, but computing the central differences is quite slow and it introduces an additional non-intuitive parameter: the step size of the central differences which also affects convergence performance.

The optimal way to go about gradient descent, is to compute the partial derivative of the cost function with respect to each parameter $\theta_i$:
\begin{equation}
\theta_j = \theta_{j}^{old} + \alpha\frac{\partial}{\partial \theta_j}J(\theta_j)
\end{equation}
Doing so for our $J(\theta_j)$ gives us:
\begin{equation}
\frac{\partial}{\partial \theta_j} J(\theta_j) = \frac{1}{m}\sum\limits_{i=1}^m(\theta^Tx_{i,:}-y_i)x_{j,:}
\end{equation}
This can now be used directly to compute the gradient for all values of $\theta$.

\paragraph{Tweaks}
In order to improve the performance of \emph{gradient descent}, it is recommended to normalize the learning data.
This is called \emph{feature scaling} and involves, centring the measurements of each feature around 0 and scaling them to $[-1,1]$.

\subsection{Normal Equation}
We will now look at an approach to directly estimate our parameters $\theta$.
This involves, setting the derivate of our cost function $h$ to zero and solving for $\theta$.

\paragraph{Design matrix:} The \emph{design matrix} $X \in \mathbb{R}^{m\times n+1}$ with $m$ the measurement count and $n$ the number of features.
As described earlier, $X$ has an extra column to consider the offset.

\paragraph{Solution:} For linear regression, $\theta$ can be computed by:
\begin{equation}
\theta = (X^TX)^{-1}X^Ty
\end{equation}

\paragraph{Compared with Gradient Descent:}
Solving a linear regression using the \emph{normal equation} approach is not necessarily the optimal way to do it.
In the following we will discuss the pros and cons:

\begin{multicols}{2}
\underline{Gradient Descent}
\begin{itemize}
\item needs to choose $\alpha$
\item is iterative
\item can handle data with large number of features,\\ i.e. large $n$
\end{itemize}

\columnbreak
\underline{Normal Equation}\\
\begin{itemize}
\item no need to choose $\alpha$
\item could not be iterative (depending on implementation)
\item computation of $(X^TX)^{-1}$\\ requires lots of memory. Still works well when $n <= 10000$
\end{itemize}
\end{multicols}


\section*{Octave Cheat Sheet}
\begin{tabular}{l|l}
\textbf{Command}&\textbf{Description}\\
\hline
pinv(A)&compute inverse of a matrix\\
A'&transpose of the matrix (new this but looks nice anyway)
\end{tabular}

\end{document}
